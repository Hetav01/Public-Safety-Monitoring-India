{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load the two CSV files annotated by two different people\n",
    "hetavLabeled = pd.read_csv('2700_comments_hetav_labeled.csv')\n",
    "anishaLabeled = pd.read_csv('2700_comments_anisha_labeled.csv')\n",
    "\n",
    "# Assuming both CSVs have a column 'label' with the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if the two files with the name '2700_comments_hetav_labeled.csv' and '2700_comments_final_hetav_labeled.csv' are identical\n",
    "# # annotations_final = pd.read_csv('2700_comments_final_hetav_labeled.csv')\n",
    "# are_identical = annotations1.equals(annotations2)\n",
    "# print(f\"Are the two files identical? {are_identical}\")\n",
    "\n",
    "# # display how many rows are different between the two files for the same id, the llm_output column has different values\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the two CSV files\n",
    "# file1 = \"2700_comments_hetav_labeled.csv\"\n",
    "# file2 = \"2700_comments_anisha_labeled.csv\"\n",
    "\n",
    "# df1 = pd.read_csv(file1)\n",
    "# df2 = pd.read_csv(file2)\n",
    "\n",
    "# # Ensure both DataFrames are sorted by 'serial_number' for comparison\n",
    "# df1 = df1.sort_values(by=\"Serial_Number\").reset_index(drop=True)\n",
    "# df2 = df2.sort_values(by=\"Serial_Number\").reset_index(drop=True)\n",
    "\n",
    "# df1[\"llm_output\"] = df1[\"llm_output\"].astype(int)\n",
    "# df2[\"llm_output\"] = df2[\"llm_output\"].astype(int)\n",
    "\n",
    "# # Rename columns in the second DataFrame to distinguish them\n",
    "# df2 = df2.rename(columns={\"llm_output\": \"llm_output_done_by_anisha\"})\n",
    "# df1 = df1.rename(columns={\"llm_output\": \"llm_output_done_by_hetav\"})\n",
    "\n",
    "# # Merge the two DataFrames on 'serial_number' to align rows\n",
    "# merged_df = pd.merge(df1, df2, on=\"Serial_Number\", suffixes=('_file1', ''))\n",
    "\n",
    "# merged_df.head()  # Display the first few rows of the merged DataFrame\n",
    "\n",
    "\n",
    "# differences = merged_df[merged_df[\"llm_output_done_by_hetav\"] != merged_df[\"llm_output_done_by_anisha\"]]\n",
    "\n",
    "# # Compute the percentage of differences\n",
    "# total_rows = len(merged_df)\n",
    "# different_rows = len(differences)\n",
    "# percentage_difference = (different_rows / total_rows) * 100\n",
    "\n",
    "# print(f\"Total rows compared: {total_rows}\")\n",
    "# print(f\"Number of differing rows: {different_rows}\")\n",
    "# print(f\"Percentage of differing rows: {percentage_difference:.2f}%\")\n",
    "\n",
    "\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# kappa_score = cohen_kappa_score(merged_df[\"llm_output_done_by_hetav\"], merged_df[\"llm_output_done_by_anisha\"])\n",
    "# print(f\"Cohen's Kappa Score: {kappa_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Label_Topic in hetavLabeled:\n",
      "Label_Topic\n",
      "Irrelevant/General Comments                   1019\n",
      "Anger or Outrage                               685\n",
      "Views on Similar Cases in the Past             264\n",
      "Socioeconomic Privilege                        258\n",
      "Judicial Accountability and Policy Demands     229\n",
      "Victim Sympathy                                157\n",
      "Public Safety                                   95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of Label_Topic in anishaLabeled:\n",
      "Label_Topic\n",
      "Irrelevant/General Comments                   1101\n",
      "Anger or Outrage                               724\n",
      "Views on Similar Cases in the Past             254\n",
      "Judicial Accountability and Policy Demands     224\n",
      "Socioeconomic Privilege                        220\n",
      "Victim Sympathy                                129\n",
      "Public Safety                                   55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#give me distribution of the Label_Topic column in the two dataframes seperately\n",
    "print(\"Distribution of Label_Topic in hetavLabeled:\")\n",
    "print(hetavLabeled['Label_Topic'].value_counts())\n",
    "print(\"\\nDistribution of Label_Topic in anishaLabeled:\")\n",
    "print(anishaLabeled['Label_Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of Label_Topic in sampled hetavLabeled:\n",
      "Label_Topic\n",
      "Anger or Outrage                              157\n",
      "Irrelevant/General Comments                   157\n",
      "Victim Sympathy                               157\n",
      "Socioeconomic Privilege                       157\n",
      "Judicial Accountability and Policy Demands    157\n",
      "Views on Similar Cases in the Past            157\n",
      "Public Safety                                  95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# I need to randomly sample 157 rows for each Label_Topic and just take all the 95 rows for the topic 'Public Safety' from the hetavLabeled dataframe\n",
    "sampled_dfs = []\n",
    "label_topics = hetavLabeled['Label_Topic'].unique()\n",
    "for topic in label_topics:\n",
    "    topic_df = hetavLabeled[hetavLabeled['Label_Topic'] == topic]\n",
    "    if topic == 'Public Safety':\n",
    "        sampled_dfs.append(topic_df)\n",
    "    else:\n",
    "        sampled_dfs.append(topic_df.sample(n=157, random_state=42))\n",
    "sampled_hetav = pd.concat(sampled_dfs)\n",
    "sampled_hetav = sampled_hetav.reset_index(drop=True)\n",
    "print(\"\\nDistribution of Label_Topic in sampled hetavLabeled:\")\n",
    "print(sampled_hetav['Label_Topic'].value_counts())\n",
    "# Save the sampled dataframe to a new CSV file\n",
    "\n",
    "sampled_hetav.to_csv('sampled_hetav_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining why I took 157, since I needed to get about 1000 comments rightly labeled again and Public Safety in my csv only had 95 counts, \n",
    "\n",
    "I took all the 95 from Public Safety and then for the others, I took 157 coz Victim Sympathy had 157.\n",
    "\n",
    "---\n",
    "\n",
    "***(157\\*6 + 95) = 1037 comments!***\n",
    "\n",
    "---\n",
    "\n",
    "Instructions from Soumyajit also mentioned to keep the data unseen and balanced for all classes, so will be removing the label column completely and redoing it in excel. \n",
    "\n",
    "Furthermore, the next step will be to jumble this shit up like crazy to add complexity and toughness.\n",
    "\n",
    "\n",
    "\n",
    "#### **I'll then pick the same 1037 comments from Anisha's file and check Kappa score. I hope labeling it again can improve the sensibility and rectify any mistakes done previously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1037 entries, 0 to 1036\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Serial_Number  1037 non-null   int64 \n",
      " 1   id             1037 non-null   object\n",
      " 2   text           1037 non-null   object\n",
      " 3   llm_output     1037 non-null   int64 \n",
      " 4   llm_model      1037 non-null   object\n",
      " 5   Label_Topic    1037 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 48.7+ KB\n"
     ]
    }
   ],
   "source": [
    "sampled_hetav.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_Number</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>llm_output</th>\n",
       "      <th>llm_model</th>\n",
       "      <th>Label_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392</td>\n",
       "      <td>UgyifOKuhdFvCvifmup4AaABAg</td>\n",
       "      <td>Money is everything</td>\n",
       "      <td>5</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Anger or Outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358</td>\n",
       "      <td>Ugxy69_uEYXk8MwbvfN4AaABAg</td>\n",
       "      <td>Well explained people's incentives by this case.</td>\n",
       "      <td>5</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Anger or Outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2705</td>\n",
       "      <td>UgyQZTUY-8yQjzXYEIx4AaABAg</td>\n",
       "      <td>Last year in Ahmedabad Gujarat we had Tathya p...</td>\n",
       "      <td>5</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Anger or Outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246</td>\n",
       "      <td>Ugy9FPYb-h1ElqB5IWd4AaABAg</td>\n",
       "      <td>Life is becoming cheaper despite of income its...</td>\n",
       "      <td>5</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Anger or Outrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2803</td>\n",
       "      <td>UgxfwCpwroGhfZcf0-p4AaABAg</td>\n",
       "      <td>Main toh kehta hoon chhodo judiciary system ko...</td>\n",
       "      <td>5</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Anger or Outrage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial_Number                          id  \\\n",
       "0           1392  UgyifOKuhdFvCvifmup4AaABAg   \n",
       "1            358  Ugxy69_uEYXk8MwbvfN4AaABAg   \n",
       "2           2705  UgyQZTUY-8yQjzXYEIx4AaABAg   \n",
       "3            246  Ugy9FPYb-h1ElqB5IWd4AaABAg   \n",
       "4           2803  UgxfwCpwroGhfZcf0-p4AaABAg   \n",
       "\n",
       "                                                text  llm_output   llm_model  \\\n",
       "0                                Money is everything           5  llama3:70b   \n",
       "1   Well explained people's incentives by this case.           5  llama3:70b   \n",
       "2  Last year in Ahmedabad Gujarat we had Tathya p...           5  llama3:70b   \n",
       "3  Life is becoming cheaper despite of income its...           5  llama3:70b   \n",
       "4  Main toh kehta hoon chhodo judiciary system ko...           5  llama3:70b   \n",
       "\n",
       "        Label_Topic  \n",
       "0  Anger or Outrage  \n",
       "1  Anger or Outrage  \n",
       "2  Anger or Outrage  \n",
       "3  Anger or Outrage  \n",
       "4  Anger or Outrage  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_hetav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_Number</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>llm_output</th>\n",
       "      <th>llm_model</th>\n",
       "      <th>Label_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2656</td>\n",
       "      <td>Ugwrftz7Bwyq2dJ2uBN4AaABAg</td>\n",
       "      <td>Good but what about person died both should be...</td>\n",
       "      <td>4</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Victim Sympathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>UgyBr7F25Vne11H5J5B4AaABAg</td>\n",
       "      <td>I know how rash driving happenes in KP,viman n...</td>\n",
       "      <td>7</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Views on Similar Cases in the Past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646</td>\n",
       "      <td>UgzWh-o6HgFdFunJlzB4AaABAg</td>\n",
       "      <td>Nobody can share her pain :loudly_crying_face:</td>\n",
       "      <td>4</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Victim Sympathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3009</td>\n",
       "      <td>UgxDeq7-v8c5g2cLTKl4AaABAg</td>\n",
       "      <td>It's a shame that helmets are still not mandat...</td>\n",
       "      <td>2</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Public Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>677</td>\n",
       "      <td>Ugx1k_82LTKWCuBngUV4AaABAg</td>\n",
       "      <td>Problem of Traffic Rule:-\\nThis is my personal...</td>\n",
       "      <td>2</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Public Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2058</td>\n",
       "      <td>Ugwa6qBYjzXqmwSzbap4AaABAg</td>\n",
       "      <td>The young and his gf newly in job erred to ven...</td>\n",
       "      <td>6</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Irrelevant/General Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1322</td>\n",
       "      <td>UgyBtc3mAFQvd-ntI3l4AaABAg</td>\n",
       "      <td>Javan ke lie boliye:crying_face:</td>\n",
       "      <td>6</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Irrelevant/General Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2726</td>\n",
       "      <td>Ugygiy2R0Sj3hMq-znF4AaABAg</td>\n",
       "      <td>Please make more videos on Prajwal Revanna mat...</td>\n",
       "      <td>6</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Irrelevant/General Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>177</td>\n",
       "      <td>Ugz3tujFlawzklSIHLd4AaABAg</td>\n",
       "      <td>The father has money so you know he gonna be f...</td>\n",
       "      <td>2</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Public Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>935</td>\n",
       "      <td>Ugxr_tRHbRlk_J9oPJN4AaABAg</td>\n",
       "      <td>Sir please west bengal doctor ka rape and murd...</td>\n",
       "      <td>7</td>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>Views on Similar Cases in the Past</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial_Number                          id  \\\n",
       "0           2656  Ugwrftz7Bwyq2dJ2uBN4AaABAg   \n",
       "1            109  UgyBr7F25Vne11H5J5B4AaABAg   \n",
       "2           1646  UgzWh-o6HgFdFunJlzB4AaABAg   \n",
       "3           3009  UgxDeq7-v8c5g2cLTKl4AaABAg   \n",
       "4            677  Ugx1k_82LTKWCuBngUV4AaABAg   \n",
       "5           2058  Ugwa6qBYjzXqmwSzbap4AaABAg   \n",
       "6           1322  UgyBtc3mAFQvd-ntI3l4AaABAg   \n",
       "7           2726  Ugygiy2R0Sj3hMq-znF4AaABAg   \n",
       "8            177  Ugz3tujFlawzklSIHLd4AaABAg   \n",
       "9            935  Ugxr_tRHbRlk_J9oPJN4AaABAg   \n",
       "\n",
       "                                                text  llm_output   llm_model  \\\n",
       "0  Good but what about person died both should be...           4  llama3:70b   \n",
       "1  I know how rash driving happenes in KP,viman n...           7  llama3:70b   \n",
       "2     Nobody can share her pain :loudly_crying_face:           4  llama3:70b   \n",
       "3  It's a shame that helmets are still not mandat...           2  llama3:70b   \n",
       "4  Problem of Traffic Rule:-\\nThis is my personal...           2  llama3:70b   \n",
       "5  The young and his gf newly in job erred to ven...           6  llama3:70b   \n",
       "6                   Javan ke lie boliye:crying_face:           6  llama3:70b   \n",
       "7  Please make more videos on Prajwal Revanna mat...           6  llama3:70b   \n",
       "8  The father has money so you know he gonna be f...           2  llama3:70b   \n",
       "9  Sir please west bengal doctor ka rape and murd...           7  llama3:70b   \n",
       "\n",
       "                          Label_Topic  \n",
       "0                     Victim Sympathy  \n",
       "1  Views on Similar Cases in the Past  \n",
       "2                     Victim Sympathy  \n",
       "3                       Public Safety  \n",
       "4                       Public Safety  \n",
       "5         Irrelevant/General Comments  \n",
       "6         Irrelevant/General Comments  \n",
       "7         Irrelevant/General Comments  \n",
       "8                       Public Safety  \n",
       "9  Views on Similar Cases in the Past  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jumble the entire rows of the sampled_hetav dataframe randomly. don't mismatch columns while jumbling, do a sanity check after jumbling to see if the netire row is intact and only the order of the rows in the dataframe is changed\n",
    "sampled_hetav_jumbled = sampled_hetav.sample(frac=1, random_state=12).reset_index(drop=True)\n",
    "sampled_hetav_jumbled.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if the jumbled rows are intact as a row and just the positional order of the rows have changed inside the dataframe\n",
    "# for i in range(len(sampled_hetav)):\n",
    "#     original_row = sampled_hetav.iloc[i]\n",
    "#     jumbled_row = sampled_hetav_jumbled[sampled_hetav_jumbled.eq(original_row).all(axis=1)]\n",
    "#     if jumbled_row.empty:\n",
    "#         print(f\"Row {i} does not match after jumbling!\")\n",
    "#     else:\n",
    "#         print(f\"Row {i} matches after jumbling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_hetav_jumbled.to_csv('sampled_hetav_labeled_jumbled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differing rows in sampled data: 160 out of 1037\n",
      "Cohen's Kappa Score for sampled data: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Find the same comments based on the same id column in anishaLabeled dataframe\n",
    "sampled_anisha = anishaLabeled[anishaLabeled['Serial_Number'].isin(sampled_hetav_jumbled['Serial_Number'])]\n",
    "sampled_anisha.head()\n",
    "\n",
    "# set both of the dataframes to have the same order of rows based on the Serial_Number column and then merge them\n",
    "sampled_anisha = sampled_anisha.set_index('Serial_Number').loc[sampled_hetav_jumbled['Serial_Number']].reset_index()\n",
    "sampled_anisha.head()\n",
    "\n",
    "# merge them\n",
    "merged_sampled = pd.merge(sampled_hetav_jumbled, sampled_anisha, on='Serial_Number', suffixes=('_hetav', '_anisha'))\n",
    "merged_sampled.head()\n",
    "\n",
    "# check how many are different in the llm_output columns\n",
    "differences_sampled = merged_sampled[merged_sampled['llm_output_hetav'] != merged_sampled['llm_output_anisha']]\n",
    "print(f\"Number of differing rows in sampled data: {len(differences_sampled)} out of {len(merged_sampled)}\")\n",
    "# Compute Cohen's Kappa Score for the sampled data\n",
    "kappa_score_sampled = cohen_kappa_score(merged_sampled['llm_output_hetav'], merged_sampled['llm_output_anisha'])\n",
    "print(f\"Cohen's Kappa Score for sampled data: {kappa_score_sampled:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Labeling is complete! 1037 comments relabeled in an unseen format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the relabeled csv file from relabel folder\n",
    "relabeledHetav = pd.read_csv('relabel/1037_relabeled_hetav.csv')\n",
    "\n",
    "# adding the label topic names based on the relabel column.\n",
    "def label_to_text(label):\n",
    "    if label == 1 or label == 1.0:\n",
    "        return \"Judicial Accountability and Policy Demands\"\n",
    "    elif label == 2 or label == 2.0:\n",
    "        return \"Public Safety\"\n",
    "    elif label == 3 or label == 3.0:\n",
    "        return \"Socioeconomic Privilege\"\n",
    "    elif label == 4 or label == 4.0:\n",
    "        return \"Victim Sympathy\"\n",
    "    elif label == 5 or label == 5.0:\n",
    "        return \"Anger or Outrage\"\n",
    "    elif label == 6 or label == 6.0:\n",
    "        return \"Irrelevant/General Comments\"\n",
    "    elif label == 7 or label == 7.0:\n",
    "        return \"Views on Similar Cases in the Past\"\n",
    "    else:\n",
    "        return \"Unknown or might need to be fixed\"\n",
    "\n",
    "relabeledHetav[\"Label_Topic\"] = relabeledHetav[\"relabel\"]\n",
    "relabeledHetav[\"Label_Topic\"] = relabeledHetav[\"Label_Topic\"].apply(label_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differing rows in relabeled data: 220 out of 1037\n",
      "Cohen's Kappa Score for relabeled data: 0.75\n"
     ]
    }
   ],
   "source": [
    "# find the same comments based on the same id column in anishaLabeled dataframe\n",
    "relabeledAnisha = anishaLabeled[anishaLabeled['Serial_Number'].isin(relabeledHetav['Serial_Number'])]\n",
    "relabeledAnisha.head()\n",
    "\n",
    "# set both of the dataframes to have the same order of rows based on the Serial_Number column and then merge them\n",
    "relabeledAnisha = relabeledAnisha.set_index('Serial_Number').loc[relabeledHetav['Serial_Number']].reset_index()\n",
    "relabeledAnisha.head()\n",
    "\n",
    "# merge them\n",
    "merged_relabeled = pd.merge(relabeledHetav, relabeledAnisha, on='Serial_Number', suffixes=('_hetav', '_anisha'))\n",
    "merged_relabeled.head()\n",
    "\n",
    "# check how many are different in the llm_output_anisha and relabel columns\n",
    "differences_relabeled = merged_relabeled[merged_relabeled['relabel'] != merged_relabeled['llm_output_anisha']]\n",
    "print(f\"Number of differing rows in relabeled data: {len(differences_relabeled)} out of {len(merged_relabeled)}\")\n",
    "\n",
    "# Compute Cohen's Kappa Score for the relabeled data\n",
    "kappa_score_relabeled = cohen_kappa_score(merged_relabeled['relabel'], merged_relabeled['llm_output_anisha'])\n",
    "print(f\"Cohen's Kappa Score for relabeled data: {kappa_score_relabeled:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the final relabel file for fine-tuning, pick some columns from the merged_relabeled dataframe and save it to a new csv file. rename the columns appropriately without suffix.\n",
    "# these are the columns to pick: id_hetav\ttext_hetav\trelabel\tllm_model_hetav\tLabel_Topic_hetav\n",
    "final_relabel = merged_relabeled[['Serial_Number', 'text_hetav', 'relabel', 'llm_model_hetav', 'Label_Topic_hetav']]\n",
    "final_relabel = final_relabel.rename(columns={\n",
    "    'Serial_Number': 'Serial_Number',\n",
    "    'text_hetav': 'text',\n",
    "    'relabel': 'relabel_llm_output',\n",
    "    'llm_model_hetav': 'llm_model',\n",
    "    'Label_Topic_hetav': 'Label_Topic'\n",
    "})\n",
    "\n",
    "\n",
    "# also as per requirements changing the relabel_llm_output column values from 1 indexed to 0 indexed, just subtract one from all.\n",
    "final_relabel['relabel_llm_output'] = final_relabel['relabel_llm_output'] - 1\n",
    "\n",
    "# Label mapping dictionary for future reference.\n",
    "label_mapping = {\n",
    "    0: \"Judicial Accountability and Policy Demands\",\n",
    "    1: \"Public Safety\",\n",
    "    2: \"Socioeconomic Privilege\",\n",
    "    3: \"Victim Sympathy\",\n",
    "    4: \"Anger or Outrage\",\n",
    "    5: \"Irrelevant/General Comments\",\n",
    "    6: \"Views on Similar Cases in the Past\"\n",
    "}\n",
    "\n",
    "final_relabel.to_csv('relabel/1037_relabeled_for_finetuning_hetav.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
