{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373a2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sd3528/anaconda3/envs/tts/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel, PeftConfig, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import LlamaForSequenceClassification\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import os\n",
    "def evaluate_model(base_model, save_path, tokenizer, test_dataset):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    compute_dtype = getattr(torch, \"float16\")\n",
    "    use_4bit = True\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=use_4bit, # Load model in 4bit\n",
    "        bnb_4bit_quant_type=\"nf4\", # Use 4bit quantization. NormalFloat4 \n",
    "        bnb_4bit_compute_dtype=compute_dtype, # Use float16 for computation\n",
    "        bnb_4bit_use_double_quant=False, # Use double quantization\n",
    "    )\n",
    "    \n",
    "    base_model = LlamaForSequenceClassification.from_pretrained(base_model, num_labels=7, device_map=None)\n",
    "    base_model.eval()\n",
    "    \n",
    "    base_model.config.pad_token_id = base_model.config.eos_token_id\n",
    "    # base_model.config.num_labels = 7\n",
    "    # Load the fine-tuned model\n",
    "    # model = LlamaForSequenceClassification.from_pretrained(save_path, num_labels=3, quantization_config=bnb_config)\n",
    "    # model.eval()\n",
    "    # model.resize_token_embeddings(len(tokenizer))\n",
    "    # model.config.pad_token_id = model.config.eos_token_id\n",
    "    # model.config.num_labels = 3\n",
    "    \n",
    "    model = PeftModel.from_pretrained(base_model, save_path)\n",
    "    model = model.merge_and_unload()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the test dataset\n",
    "    def tokenize_function(examples):\n",
    "      return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test_dataset = tokenized_test_dataset.rename_column(\"label\", \"labels\") \n",
    "    tokenized_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    # Create DataLoader for evaluation\n",
    "    from torch.utils.data import DataLoader\n",
    "    eval_dataloader = DataLoader(tokenized_test_dataset, batch_size=16)\n",
    "\n",
    "    # Move model to device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "        \n",
    "    test_dataset_arr = []\n",
    "    # Evaluation loop\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, axis=1)\n",
    "            \n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # save the text and label\n",
    "            for i in range(len(preds)):\n",
    "                test_dataset_arr.append({\n",
    "                    'text': tokenizer.decode(input_ids[i], skip_special_tokens=True),\n",
    "                    'pred': preds[i].item(),\n",
    "                    'label': labels[i].item()\n",
    "                })\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds)#, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "    confusion = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    \n",
    "    # kill model\n",
    "    # del model\n",
    "    # del base_model\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    return accuracy, report, test_dataset_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85aa7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/home/sd3528/hetav-2/data/eval_30_each.csv')\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\").astype(str)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2754dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-majority-sampling/model\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46992078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 210/210 [00:00<00:00, 14547.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69        30\n",
      "           1       0.91      0.33      0.49        30\n",
      "           2       0.85      0.73      0.79        30\n",
      "           3       1.00      0.70      0.82        30\n",
      "           4       0.38      0.67      0.48        30\n",
      "           5       0.39      0.60      0.47        30\n",
      "           6       0.91      0.67      0.77        30\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.73      0.63      0.64       210\n",
      "weighted avg       0.73      0.63      0.64       210\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  0  0  0  7  2  0]\n",
      " [ 2 10  0  0 10  8  0]\n",
      " [ 0  0 22  0  4  4  0]\n",
      " [ 1  0  1 21  3  4  0]\n",
      " [ 6  1  1  0 20  2  0]\n",
      " [ 1  0  2  0  7 18  2]\n",
      " [ 0  0  0  0  2  8 20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6285714285714286,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.68      0.70      0.69        30\\n           1       0.91      0.33      0.49        30\\n           2       0.85      0.73      0.79        30\\n           3       1.00      0.70      0.82        30\\n           4       0.38      0.67      0.48        30\\n           5       0.39      0.60      0.47        30\\n           6       0.91      0.67      0.77        30\\n\\n    accuracy                           0.63       210\\n   macro avg       0.73      0.63      0.64       210\\nweighted avg       0.73      0.63      0.64       210\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base\n",
    "test_df = pd.read_csv('/home/sd3528/hetav-2/data/eval_30_each.csv')\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\").astype(str)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-org-vfinal/model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "evaluate_model(\n",
    "    base_model=\"meta-llama/Meta-Llama-3-8B\",\n",
    "    save_path=\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-org-vfinal/model\",\n",
    "    tokenizer=tokenizer,\n",
    "    test_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6183edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 210/210 [00:00<00:00, 20761.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7048\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59        30\n",
      "           1       0.85      0.73      0.79        30\n",
      "           2       0.81      0.73      0.77        30\n",
      "           3       1.00      0.70      0.82        30\n",
      "           4       0.44      0.70      0.54        30\n",
      "           5       0.59      0.80      0.68        30\n",
      "           6       0.96      0.73      0.83        30\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.76      0.70      0.72       210\n",
      "weighted avg       0.76      0.70      0.72       210\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  0  1  0 12  1  0]\n",
      " [ 1 22  1  0  3  3  0]\n",
      " [ 1  1 22  0  3  3  0]\n",
      " [ 1  1  0 21  4  3  0]\n",
      " [ 5  2  1  0 21  1  0]\n",
      " [ 0  0  2  0  3 24  1]\n",
      " [ 0  0  0  0  2  6 22]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7047619047619048,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.67      0.53      0.59        30\\n           1       0.85      0.73      0.79        30\\n           2       0.81      0.73      0.77        30\\n           3       1.00      0.70      0.82        30\\n           4       0.44      0.70      0.54        30\\n           5       0.59      0.80      0.68        30\\n           6       0.96      0.73      0.83        30\\n\\n    accuracy                           0.70       210\\n   macro avg       0.76      0.70      0.72       210\\nweighted avg       0.76      0.70      0.72       210\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority Sample\n",
    "test_df = pd.read_csv('/home/sd3528/hetav-2/data/eval_30_each.csv')\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\").astype(str)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-certainty-vfinal/model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "evaluate_model(\n",
    "    base_model=\"meta-llama/Meta-Llama-3-8B\",\n",
    "    save_path=\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-certainty-vfinal/model\",\n",
    "    tokenizer=tokenizer,\n",
    "    test_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c81e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # minority sample\n",
    "\n",
    "# test_df = pd.read_csv('/home/sd3528/hetav-2/data/eval_30_each.csv')\n",
    "# test_df[\"text\"] = test_df[\"text\"].fillna(\"\").astype(str)\n",
    "# test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-minority-sampling/model\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# evaluate_model(\n",
    "#     base_model=\"meta-llama/Meta-Llama-3-8B\",\n",
    "#     save_path=\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-minority-sampling/model\",\n",
    "#     tokenizer=tokenizer,\n",
    "#     test_dataset=test_dataset\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7986715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 402/402 [00:00<00:00, 23599.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7139\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.56        33\n",
      "           1       0.67      0.83      0.74        12\n",
      "           2       0.67      0.85      0.75        47\n",
      "           3       0.75      0.82      0.78        33\n",
      "           4       0.62      0.70      0.66       105\n",
      "           5       0.80      0.68      0.74       133\n",
      "           6       0.83      0.77      0.80        39\n",
      "\n",
      "    accuracy                           0.71       402\n",
      "   macro avg       0.72      0.73      0.72       402\n",
      "weighted avg       0.72      0.71      0.71       402\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0 16  2  0]\n",
      " [ 0 10  0  0  2  0  0]\n",
      " [ 0  0 40  0  5  2  0]\n",
      " [ 0  0  0 27  5  1  0]\n",
      " [ 3  2  6  6 74 11  3]\n",
      " [ 3  3 13  3 17 91  3]\n",
      " [ 0  0  1  0  1  7 30]]\n"
     ]
    }
   ],
   "source": [
    "# minority sample\n",
    "\n",
    "test_df = pd.read_csv('/home/sd3528/hetav-2/data/margin/valid_minority_sampling_w_topic.csv')\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\").astype(str)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-minority-sampling-v2/model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "_ , _ ,test_dataset_arr = evaluate_model(\n",
    "    base_model=\"meta-llama/Meta-Llama-3-8B\",\n",
    "    save_path=\"/home/sd3528/hetav-2/experiments/llama3-8b-qlora-v2-minority-sampling-v2/model\",\n",
    "    tokenizer=tokenizer,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "pd.DataFrame(test_dataset_arr).to_csv('/home/sd3528/hetav-2/data/margin/margin_inference.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc29fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
